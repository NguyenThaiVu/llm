{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9ddfda",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will visualize the architecture of Pytorch model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42baab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import sys \n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(123)\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import Llama3Model, generate, text_to_token_ids, token_ids_to_text\n",
    "from tokenizer import Llama3Tokenizer, ChatFormat, clean_text\n",
    "from model import LLAMA32_CONFIG_1B, LLAMA32_CONFIG_3B\n",
    "from model import compute_rope_params\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d573957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Hyper-parameter =====\n",
    "MODEL_FILE = \"model/llama3.2-1B-base.pth\"\n",
    "MODEL_CONTEXT_LENGTH = 8192  # Support up to 131_072\n",
    "MAX_NEW_TOKENS = 100\n",
    "TEMPERATURE = 0.\n",
    "TOP_K = 1\n",
    "TOKENIZER_FILE = \"tokenizer.model\"\n",
    "\n",
    "device = \"cpu\"\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a6f90",
   "metadata": {},
   "source": [
    "# 1. Layer summarize (text-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc780404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "if os.path.exists(MODEL_FILE) == False:\n",
    "    print(f\"[ERROR] Model does not exist !!!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "if \"1B\" in MODEL_FILE:\n",
    "    llama32_config = LLAMA32_CONFIG_1B\n",
    "elif \"3B\" in MODEL_FILE:\n",
    "    llama32_config = LLAMA32_CONFIG_3B\n",
    "else:\n",
    "    print(f\"[ERROR] Check model file again !!!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "llama32_config[\"context_length\"] = MODEL_CONTEXT_LENGTH\n",
    "\n",
    "model = Llama3Model(llama32_config)\n",
    "checkpoint = torch.load(MODEL_FILE, weights_only=True, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully from {MODEL_FILE}\")\n",
    "print(f\"Model size (in GB): {sum(p.numel() for p in model.parameters())*4/1024/1024/1024:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "input_seq_len = 16\n",
    "vocab_size = model.cfg[\"vocab_size\"]\n",
    "dummy_input = torch.randint(0, vocab_size, (batch_size, input_seq_len),\\\n",
    "                            dtype=torch.int32).to(device)\n",
    "\n",
    "print(f\"Shape of dummy input: {dummy_input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82954b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(batch_size, input_seq_len), dtypes=[torch.int32],\\\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3c1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2687f2b0",
   "metadata": {},
   "source": [
    "# 2. Graph visualizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "input_seq_len = 16\n",
    "vocab_size = model.cfg[\"vocab_size\"]\n",
    "dummy_input = torch.randint(0, vocab_size, (batch_size, input_seq_len),\\\n",
    "                            dtype=torch.int32).to(device)\n",
    "\n",
    "print(f\"Shape of dummy input: {dummy_input.shape}\")\n",
    "print(dummy_input.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516707d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(dummy_input)\n",
    "print(f\"Shape of model output: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = draw_graph(\n",
    "    model,\n",
    "    input_data=dummy_input,\n",
    "    expand_nested=True,       # expand TransformerBlocks etc.\n",
    "    depth=1,                  # how deep to expand (increase for more detail)\n",
    "    save_graph=True,          # saves to file\n",
    "    filename=\"visualization/llama_forward\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dc4f49d",
   "metadata": {},
   "source": [
    "# 3. Loading weight of first Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_block_0 = model.trf_blocks[0]\n",
    "for idx, (name, param) in enumerate(transformer_block_0.named_parameters()):\n",
    "    print(f\"{idx}: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46111c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27154a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "input_seq_len = 16\n",
    "embed_dim = 2048\n",
    "vocab_size = model.cfg[\"vocab_size\"]\n",
    "dummy_input = torch.randint(0, vocab_size, (batch_size, input_seq_len, embed_dim),\\\n",
    "                            dtype=torch.bfloat16).to(device)\n",
    "\n",
    "print(f\"Shape of dummy input: {dummy_input.shape}\")\n",
    "mask = torch.triu(torch.ones(input_seq_len, input_seq_len, device=device,\\\n",
    "                             dtype=torch.bool), diagonal=1)\n",
    "cos = torch.zeros((input_seq_len, model.cfg[\"emb_dim\"]//model.cfg[\"n_heads\"]),\\\n",
    "                  device=device, dtype=torch.bfloat16)\n",
    "sin = torch.zeros((input_seq_len, model.cfg[\"emb_dim\"]//model.cfg[\"n_heads\"]),\\\n",
    "                  device=device, dtype=torch.bfloat16)\n",
    "                               \n",
    "output_transformer_block = transformer_block_0(dummy_input, mask, cos, sin)\n",
    "print(f\"Shape of transformer output: {output_transformer_block.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockWrapper(nn.Module):\n",
    "    def __init__(self, transformer_block):\n",
    "        super().__init__()\n",
    "        self.block = transformer_block\n",
    "\n",
    "    def forward(self, x, mask, cos, sin):\n",
    "        return self.block(x, mask, cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = BlockWrapper(transformer_block_0)\n",
    "\n",
    "# Draw the forward graph\n",
    "graph = draw_graph(\n",
    "    wrapper,\n",
    "    input_data=(dummy_input, mask, cos, sin),\n",
    "    expand_nested=True,\n",
    "    depth=2,\n",
    "    save_graph=True,\n",
    "    filename=\"visualization/transformer_block\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c30b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
