{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9ddfda",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will visualize the architecture of Pytorch model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42baab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(123)\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.model import Llama3Model, generate, text_to_token_ids, token_ids_to_text\n",
    "from utils.tokenizer import Llama3Tokenizer, ChatFormat, clean_text\n",
    "from utils.model import LLAMA32_CONFIG_1B, LLAMA32_CONFIG_3B\n",
    "from utils.model import compute_rope_params\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils.quantization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d573957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Hyper-parameter =====\n",
    "MODEL_FILE = \"model/llama3.2-1B-instruct.pth\"\n",
    "MODEL_CONTEXT_LENGTH = 8192  # Support up to 131_072\n",
    "MAX_NEW_TOKENS = 100\n",
    "TEMPERATURE = 0.\n",
    "TOP_K = 1\n",
    "TOKENIZER_FILE = \"model/tokenizer.model\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a6f90",
   "metadata": {},
   "source": [
    "# 1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc780404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from model/llama3.2-1B-instruct.pth\n",
      "Model size (in GB): 5.58\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "if os.path.exists(MODEL_FILE) == False:\n",
    "    print(f\"[ERROR] Model does not exist !!!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "if \"1B\" in MODEL_FILE:\n",
    "    llama32_config = LLAMA32_CONFIG_1B\n",
    "elif \"3B\" in MODEL_FILE:\n",
    "    llama32_config = LLAMA32_CONFIG_3B\n",
    "else:\n",
    "    print(f\"[ERROR] Check model file again !!!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "llama32_config[\"context_length\"] = MODEL_CONTEXT_LENGTH\n",
    "\n",
    "model = Llama3Model(llama32_config)\n",
    "checkpoint = torch.load(MODEL_FILE, weights_only=True, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully from {MODEL_FILE}\")\n",
    "print(f\"Model size (in GB): {sum(p.numel() for p in model.parameters())*4/1024/1024/1024:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f4c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dummy input: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input_seq_len = 16\n",
    "vocab_size = model.cfg[\"vocab_size\"]\n",
    "dummy_input = torch.randint(0, vocab_size, (batch_size, input_seq_len),\\\n",
    "                            dtype=torch.int32).to(device)\n",
    "\n",
    "print(f\"Shape of dummy input: {dummy_input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82954b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "Llama3Model                                   [1, 16]                   [1, 16, 128256]           --\n",
       "├─Embedding: 1-1                              [1, 16]                   [1, 16, 2048]             262,668,288\n",
       "├─ModuleList: 1-2                             --                        --                        --\n",
       "│    └─TransformerBlock: 2-1                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-1                      [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-2        [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-3                      [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-4                  [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-2                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-5                      [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-6        [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-7                      [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-8                  [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-3                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-9                      [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-10       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-11                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-12                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-4                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-13                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-14       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-15                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-16                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-5                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-17                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-18       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-19                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-20                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-6                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-21                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-22       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-23                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-24                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-7                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-25                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-26       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-27                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-28                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-8                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-29                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-30       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-31                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-32                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-9                  [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-33                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-34       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-35                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-36                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-10                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-37                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-38       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-39                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-40                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-11                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-41                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-42       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-43                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-44                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-12                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-45                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-46       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-47                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-48                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-13                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-49                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-50       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-51                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-52                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-14                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-53                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-54       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-55                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-56                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-15                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-57                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-58       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-59                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-60                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "│    └─TransformerBlock: 2-16                 [1, 16, 2048]             [1, 16, 2048]             --\n",
       "│    │    └─RMSNorm: 3-61                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─GroupedQueryAttention: 3-62       [1, 16, 2048]             [1, 16, 2048]             10,485,760\n",
       "│    │    └─RMSNorm: 3-63                     [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "│    │    └─FeedForward: 3-64                 [1, 16, 2048]             [1, 16, 2048]             50,331,648\n",
       "├─RMSNorm: 1-3                                [1, 16, 2048]             [1, 16, 2048]             2,048\n",
       "├─Linear: 1-4                                 [1, 16, 2048]             [1, 16, 128256]           262,668,288\n",
       "========================================================================================================================\n",
       "Total params: 1,498,482,688\n",
       "Trainable params: 1,498,482,688\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.50\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 36.78\n",
       "Params size (MB): 2996.97\n",
       "Estimated Total Size (MB): 3033.75\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(batch_size, input_seq_len), dtypes=[torch.int32],\\\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3c1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dc4f49d",
   "metadata": {},
   "source": [
    "# 2. Loading weight of first Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbd988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: att.W_key.weight | Size: torch.Size([512, 2048])\n",
      "1: att.W_value.weight | Size: torch.Size([512, 2048])\n",
      "2: att.W_query.weight | Size: torch.Size([2048, 2048])\n",
      "3: att.out_proj.weight | Size: torch.Size([2048, 2048])\n",
      "4: ff.fc1.weight | Size: torch.Size([8192, 2048])\n",
      "5: ff.fc2.weight | Size: torch.Size([8192, 2048])\n",
      "6: ff.fc3.weight | Size: torch.Size([2048, 8192])\n",
      "7: norm1.weight | Size: torch.Size([2048])\n",
      "8: norm2.weight | Size: torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "transformer_block_0 = model.trf_blocks[0]\n",
    "for idx, (name, param) in enumerate(transformer_block_0.named_parameters()):\n",
    "    print(f\"{idx}: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46111c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6645228a",
   "metadata": {},
   "source": [
    "## 2.1. Quantization single weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb0da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix: torch.Size([2048, 2048])\n",
      "Dtype: torch.bfloat16\n",
      "Min: -0.67578125, Max: 0.58203125\n"
     ]
    }
   ],
   "source": [
    "matrix = transformer_block_0.att.W_query.weight.data\n",
    "\n",
    "print(f\"Shape of matrix: {matrix.shape}\")\n",
    "print(f\"Dtype: {matrix.dtype}\")\n",
    "print(f\"Min: {matrix.min().item()}, Max: {matrix.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57f622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix_quantized: torch.Size([2048, 2048])\n",
      "Dtype: torch.int8\n",
      "Min: -128, Max: 126\n"
     ]
    }
   ],
   "source": [
    "num_bits = 8\n",
    "\n",
    "scale, zero_point = compute_quantization_param(matrix, num_bits)\n",
    "# print(f\"Scale: {scale}, Zero point: {zero_point}\")\n",
    "\n",
    "matrix_quantized = quantize_tensor(matrix, scale, zero_point, num_bits)\n",
    "print(f\"Shape of matrix_quantized: {matrix_quantized.shape}\")\n",
    "print(f\"Dtype: {matrix_quantized.dtype}\")\n",
    "print(f\"Min: {matrix_quantized.min().item()}, Max: {matrix_quantized.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eac71d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix_dequantized: torch.Size([2048, 2048])\n",
      "Dtype: torch.float32\n",
      "MSE error: 0.000002\n"
     ]
    }
   ],
   "source": [
    "matrix_dequantized = dequantize_tensor(matrix_quantized, scale, zero_point)\n",
    "print(f\"Shape of matrix_dequantized: {matrix_dequantized.shape}\")\n",
    "print(f\"Dtype: {matrix_dequantized.dtype}\")\n",
    "\n",
    "mse_error = nn.MSELoss()(matrix, matrix_dequantized).item()\n",
    "print(f\"MSE error: {mse_error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb99343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97301eeb",
   "metadata": {},
   "source": [
    "## 2.2. Quantization activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cba085b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Llama3Tokenizer(TOKENIZER_FILE)\n",
    "\n",
    "def get_embedding_of_text(input_text:str, model,\\\n",
    "                          tokenizer, device:str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Function to get the embedding output of input text\n",
    "    \"\"\"\n",
    "    input_ids = text_to_token_ids(input_text, tokenizer)\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.int32).to(device)\n",
    "    with torch.no_grad():\n",
    "        emb_output = model.tok_emb(input_ids)\n",
    "    return emb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f040d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_embedding: torch.Size([1, 8, 2048]), Dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_204417/3380844106.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids, dtype=torch.int32).to(device)\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is the capital of VietNam?\"\n",
    "input_seq_len = len(text_to_token_ids(input_text, tokenizer))\n",
    "\n",
    "input_embedding = get_embedding_of_text(input_text, model, tokenizer, device)\n",
    "print(f\"Shape of input_embedding: {input_embedding.shape}, Dtype: {input_embedding.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e200a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W_query: torch.Size([2048, 2048]), Dtype: torch.bfloat16\n",
      "Shape of query_output: torch.Size([1, 8, 2048]), Dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "W_query = transformer_block_0.att.W_query.weight.data\n",
    "print(f\"Shape of W_query: {W_query.shape}, Dtype: {W_query.dtype}\")\n",
    "\n",
    "query_output = torch.matmul(input_embedding, W_query.T)\n",
    "print(f\"Shape of query_output: {query_output.shape}, Dtype: {query_output.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dea60e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W_query_quantized: torch.Size([2048, 2048]),        Dtype: torch.int8\n",
      "Shape of W_query_dequantized: torch.Size([2048, 2048]),        Dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "scale, zero_point = compute_quantization_param(W_query, num_bits)\n",
    "W_query_quantized = quantize_tensor(W_query, scale, zero_point, num_bits)\n",
    "print(f\"Shape of W_query_quantized: {W_query_quantized.shape},\\\n",
    "        Dtype: {W_query_quantized.dtype}\")\n",
    "\n",
    "W_query_dequantized = dequantize_tensor(W_query_quantized, scale, zero_point, output_dtype=W_query.dtype)\n",
    "print(f\"Shape of W_query_dequantized: {W_query_dequantized.shape},\\\n",
    "        Dtype: {W_query_dequantized.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecff5d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query_output_dequantized: torch.Size([1, 8, 2048]), Dtype: torch.bfloat16\n",
      "MSE error: 0.000002\n",
      "L2 error: 0.164062\n"
     ]
    }
   ],
   "source": [
    "query_output_dequantized = torch.matmul(input_embedding, W_query_dequantized.T)\n",
    "print(f\"Shape of query_output_dequantized: {query_output_dequantized.shape}, Dtype: {query_output_dequantized.dtype}\")\n",
    "\n",
    "mse_error = nn.MSELoss()(query_output, query_output_dequantized).item()\n",
    "l2_error = torch.norm(query_output - query_output_dequantized, p=2).item()\n",
    "print(f\"MSE error: {mse_error:.6f}\")\n",
    "print(f\"L2 error: {l2_error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d564910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681b661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
